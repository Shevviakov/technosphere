{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 5. Линейные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import random as pr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as pl\n",
    "import sklearn.cross_validation as cv\n",
    "import sklearn.metrics as sm\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачитываем результат 4 домашки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load(\"out_4.dat.npz\")\n",
    "users = data[\"users\"]\n",
    "X_dataset = data[\"data\"].reshape(1,)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачитываем категории пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_SET_URL = \"twitter_train.csv\"\n",
    "EXAMPLE_SET_URL = \"twitter_example.csv\"\n",
    "df_users_train = pd.read_csv(TRAINING_SET_URL, sep=\",\", header=0)\n",
    "df_users_ex = pd.read_csv(EXAMPLE_SET_URL, sep=\",\", header=0)\n",
    "df_users_ex['cls'] = None\n",
    "df_users = pd.concat([df_users_train, df_users_ex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель строим для пользователей из twitter_train, нужно выбрать этих пользователей из матрицы из 4 ДЗ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO check this code\n",
    "train_users = df_users_train[\"uid\"].values\n",
    "ix = np.in1d(users, train_users).reshape(users.shape)\n",
    "X = X_dataset[np.where(ix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7199x262259 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 2307528 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем целевую переменную: Делаем join списка пользователей из ДЗ4 с обучающей выборкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting training set: (7199x262259) feature matrix, 7199 target vector\n"
     ]
    }
   ],
   "source": [
    "Y = df_users_train['cls'].values\n",
    "print \"Resulting training set: (%dx%d) feature matrix, %d target vector\" % (X.shape[0], X.shape[1], Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы исследовать, как ведут себя признаки, построим распределение количества ненулевых признаков у пользователей, чтобы убедиться, что он удовлетворяет закону Ципфа. Для этого построим гистограмму в логарифмических осях. [Подсказка](http://anokhin.github.io/img/sf1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7199x262259 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 2307528 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEHCAYAAABCwJb2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d7f113350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_log_hist(x):\n",
    "    \"\"\"Draw tokens histogram in log scales\"\"\"\n",
    "    feat_cnt = x.sum(axis=0).tolist()[0]\n",
    "    hist = np.histogram(feat_cnt, bins = 1000)\n",
    "    plt.loglog(hist[1][:-1],hist[0],'o', ms = 3)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return np.array(feat_cnt)\n",
    "\n",
    "features_counts = draw_log_hist(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем отбор признаков. В самом простом случае просто удаляем признаки, имеющие ненулевое значение у менее, чем 100 пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = X.tocsc()[:, [x for x in xrange(len(features_counts)) if features_counts[x] > 100]].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7199, 5006)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Пришлось сделать такой костыль для list comprehension в ячейке сверху, потому что оригинал выдавал массив [7199 x 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант задания генерируется на основании вашего ника в техносфере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My homework 5 algorithm is: Logistic regression with L2 regularization optimized by Newton method\n"
     ]
    }
   ],
   "source": [
    "USER_NAME = \"d.shevyakov\"\n",
    "OPTIMIZATION_ALGORITHMS = [\"stochastic gradient descent\", \"Newton method\"]\n",
    "REGULARIZATIONS = [\"L1\", \"L2\"]\n",
    "\n",
    "print \"My homework 5 algorithm is: Logistic regression with %s regularization optimized by %s\" % (\n",
    "    REGULARIZATIONS[hash(USER_NAME) % 2],\n",
    "    OPTIMIZATION_ALGORITHMS[hash(USER_NAME[::-1]) % 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем выбранный алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    '''\n",
    "    Logistic regression with parameters:\n",
    "    'alpha'   : learning_rate (default = 1.)\n",
    "    'C'  : regularization coeff (~ 1 / lambda) (default = 1.)\n",
    "    'epsilon' : stop-tolerance (default = 1e-3)\n",
    "    'max_iter': limit of iterations (default = 100)\n",
    "    'initialize' : option for choosing initial theta values, 'zeros', 'random' or 'features' (default = 'zeros')\n",
    "    'verbose' : level of outputs (default 1)\n",
    "    'scale' : scaling X (default True)\n",
    "    '''\n",
    "    def __init__(self, alpha = 1., epsilon = 1e-3, verbose = 1, \\\n",
    "                 C = 1., max_iter = 100, init = 'zeros', scale = True):        \n",
    "        self.alpha = alpha\n",
    "        self.lambd = 1.\n",
    "        self.epsilon = epsilon\n",
    "        self.verbose = verbose\n",
    "        self.C = C\n",
    "        self.max_iter = max_iter\n",
    "        self.init = init\n",
    "        self.scale = scale\n",
    "        \n",
    "        if self.verbose >= 1: \n",
    "            print '#####################\\nLogistic Regression: initialized with parameters:'\n",
    "            print '%s\\t:\\t%f\\n%s\\t:\\t%f\\n%s\\t:\\t%f\\n%s\\t:\\t%s\\n%s:\\t%f\\n%s\\t:\\t%f\\n%s\\t:%s' \\\n",
    "            % ('alpha', self.alpha, 'C', self.C, 'epsilon', self.epsilon, \\\n",
    "               'initial', self.init, 'max_iter', self.max_iter, 'verbose', self.verbose, 'scale', self.scale)\n",
    "    \n",
    "    def _add_bias(self, X):\n",
    "        bias = np.ones(shape=(self.L, 1))\n",
    "        added = np.concatenate((bias, X), axis = 1)\n",
    "        reshaped = np.reshape(added, (self.L, self.N + 1))\n",
    "        if self.verbose == 2: \n",
    "            print '# _add_bias #'\n",
    "            print 'X: ', X.shape\n",
    "            print 'bias: ', bias.shape\n",
    "        return reshaped\n",
    "        \n",
    "    def _sigmoid(self, z):\n",
    "        return 1./ (1. + np.exp(-z))\n",
    "    \n",
    "    def _h(self, theta, X):\n",
    "        h = self._sigmoid(np.dot(X, theta))\n",
    "        h = np.abs(h - 1e-6)\n",
    "        if self.verbose == 2: \n",
    "            print 'h:', h.shape\n",
    "            print '# h #'            \n",
    "        return h\n",
    "    \n",
    "    def _gradient(self, theta, X, y):\n",
    "        if self.verbose == 2:\n",
    "            print '# gradient #'\n",
    "            print 'theta:', theta.shape\n",
    "            print 'X:', X.shape\n",
    "            print 'y:', y.shape\n",
    "        gradient = np.ndarray(shape = theta.shape)        \n",
    "        gradient[0, :] = (self.C / self.L) * np.dot(np.transpose(X), self._sigmoid(np.dot(X, theta)) - y)[0, :] \n",
    "        gradient[1:, :] = (self.C / self.L) * np.dot(np.transpose(X), self._sigmoid(np.dot(X, theta)) - y)[1:, :] + self.lambd * theta[1:, :] \n",
    "        return gradient\n",
    "    \n",
    "    def _hessian(self, theta, X):\n",
    "        \n",
    "        X_T = np.transpose(X)\n",
    "        H = self._h(theta, X)\n",
    "        S = np.diag((np.multiply(H, 1 - H)).ravel())\n",
    "        SX = np.dot(S, X)\n",
    "        X_TSX = np.dot(X_T, SX)\n",
    "        reg = np.eye(self.N + 1)\n",
    "        reg[0, 0] = 0  \n",
    "        hessian = (self.C / self.L) * X_TSX + reg \n",
    "        \n",
    "        if self.verbose == 2: \n",
    "            print '# hessian #'\n",
    "            print 'X_T:', X_T.shape\n",
    "            print 'h:', H.shape\n",
    "            print 'S:', S.shape\n",
    "            print 'Hessian:', hessian.shape\n",
    "        \n",
    "        return hessian\n",
    "    \n",
    "    def _new_step(self, hessian, gradient):\n",
    "        try:\n",
    "            d = np.linalg.solve(hessian, - gradient)\n",
    "        except np.linalg.LinAlgError:\n",
    "            d = np.linalg.lstsq(hessian, - gradient)\n",
    "        finally:\n",
    "            d = - np.dot(np.linalg.pinv(hessian), gradient)\n",
    "\n",
    "        return d\n",
    "    \n",
    "    def _J(self, theta, X, y):\n",
    "        if self.verbose == 2: print '# J #'\n",
    "        J = (self.C / self.L) * \\\n",
    "            (- np.dot(np.transpose(y) , np.log(self._h(theta, X))) \\\n",
    "             - np.dot(np.transpose(1 - y),  np.log(1 - self._h(theta, X)))) \\\n",
    "             + self.lambd * np.sum(np.square(theta))\n",
    "        if self.verbose == 2: print 'J:', J.shape\n",
    "        return J\n",
    "    \n",
    "    def _initial_theta(self, X, y):\n",
    "        theta = 0\n",
    "        if self.init == 'features':\n",
    "            theta = np.ndarray(shape = (self.N + 1,1))\n",
    "            theta_ = [1] * (self.N + 1)\n",
    "            for j in range(self.N + 1):\n",
    "                theta_[j] = np.inner(y[:, 0], X[:, j]) / np.inner(X[:, j], X[:, j])\n",
    "            theta[:, 0] = theta_\n",
    "            \n",
    "        elif self.init == 'random':\n",
    "            theta = np.random.uniform(low = -1./(2*(self.N + 1)), high = 1./(2*(self.N + 1)),size = (self.N + 1, 1))\n",
    "        \n",
    "        elif self.init == 'zeros':\n",
    "            theta = np.zeros(shape = (self.N + 1,1))\n",
    "\n",
    "        if self.verbose == 2: print 'initial theta:', theta\n",
    "        return theta\n",
    "    \n",
    "    def _newton(self, X, y):\n",
    "        theta = self._initial_theta(X, y)\n",
    "        k = 0\n",
    "        J = self._J(theta, X, y)\n",
    "        self.Js = [J[0]]\n",
    "        if self.verbose >= 1: print 'Iteration :%d\\t J:%f' %(k, J)\n",
    "        while (k < self.max_iter):\n",
    "            k += 1\n",
    "            gradient = self._gradient(theta, X, y)\n",
    "            hessian = self._hessian(theta, X)\n",
    "            d = self._new_step(hessian, gradient)\n",
    "            theta_new = theta + self.alpha * d\n",
    "            J_new = self._J(theta_new, X, y)\n",
    "            if np.max(abs(theta_new - theta)) < self.epsilon or (J_new >= J):\n",
    "                break\n",
    "            theta = theta_new\n",
    "            J = J_new\n",
    "            self.Js.append(J[0])\n",
    "            if self.verbose >= 1: print 'Iteration :%d\\t J:%f' %(k, J)\n",
    "        return theta\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.L, self.N = X.shape\n",
    "        if self.scale:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            self._X = scaler.fit_transform(X)\n",
    "        self._X = self._add_bias(self._X)\n",
    "        self.theta_ = self._newton(self._X, y)\n",
    "        if self.verbose >= 1: print 'Logistic Regression: fit finished!\\n#####################'\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):        \n",
    "        self.L, self.N = X.shape\n",
    "        if self.scale:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            self._X = scaler.fit_transform(X)\n",
    "        self._X = self._add_bias(self._X)\n",
    "        return self._h(self.theta_ ,self._X)#.T.tolist()[0]\n",
    "    \n",
    "    def predict(self, X = None, threshold = .5):\n",
    "        if X == None:\n",
    "            X = self._X\n",
    "        else:\n",
    "            if self.scale:\n",
    "                from sklearn.preprocessing import StandardScaler\n",
    "                scaler = StandardScaler()\n",
    "                self._X = scaler.fit_transform(X)\n",
    "            self.L, self.N = X.shape\n",
    "            X = self._add_bias(self._X)\n",
    "\n",
    "        return (self._h(self.theta_, X) > threshold)#.T.tolist()[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class LogisticRegression():\n",
    "#    \n",
    "#    def fit(self, X, Y=None):\n",
    "#        return self\n",
    "#    \n",
    "#    def predict_proba(self, X):\n",
    "#        import numpy.random as nr\n",
    "#        return nr.random((X.shape[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем метрику качества, используемую в соревновании: площадь под ROC кривой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auroc(y_prob, y_true):\n",
    "    from itertools import product\n",
    "\n",
    "    y_true_pos_inds = [i for i, y in enumerate(y_true) if y == 1]\n",
    "    y_true_neg_inds = [i for i, y in enumerate(y_true) if y != 1]\n",
    "    \n",
    "    y_pos = [y_prob[i] for i in y_true_pos_inds]\n",
    "    y_neg = [y_prob[i] for i in y_true_neg_inds]\n",
    "    \n",
    "    _product = list(product(y_pos, y_neg))\n",
    "    _differencies = map(lambda (x, y): x - y, _product)\n",
    "    area = np.mean(np.greater(_differencies, 0) + .5 * (np.equal(_differencies, 0)))\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку с помощью методики кросс-валидации для того, чтобы настроить параметр регуляризации $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1_train, X1_holdout, y_train, y_holdout = train_test_split(X1, Y, test_size = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "Logistic Regression: initialized with parameters:\n",
      "alpha\t:\t1.000000\n",
      "C\t:\t0.100000\n",
      "epsilon\t:\t0.001000\n",
      "initial\t:\tzeros\n",
      "max_iter:\t100.000000\n",
      "verbose\t:\t1.000000\n",
      "scale\t:True\n",
      "Iteration :0\t J:0.069315\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3023) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-906e86505517>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mX1_train_tune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX1_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_tune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mLR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time LR.fit(X1_train_tune, Y_train_tune)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauroc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m'C:%f\\tinit:%s\\tscale:%s\\tscore:%f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dima/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dima/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/dima/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dima/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1174\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-8babe3eccc9a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_bias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_newton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Logistic Regression: fit finished!\\n#####################'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-8babe3eccc9a>\u001b[0m in \u001b[0;36m_newton\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mk\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0mhessian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-8babe3eccc9a>\u001b[0m in \u001b[0;36m_gradient\u001b[1;34m(self, theta, X, y)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m'y:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mgradient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mgradient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3023) into shape (1)"
     ]
    }
   ],
   "source": [
    "params = {'C' : [0.1, 1, 10, 100, 1000],\n",
    "          'init' : ['zeros', 'random', 'features'],\n",
    "          'scale': ['True', 'False']}\n",
    "best_score = 0.\n",
    "C_opt = None\n",
    "init_opt = None\n",
    "scale_opt = None\n",
    "for c in params['C']:\n",
    "    for init in params['init']:\n",
    "        for scale in params['scale']:\n",
    "            X1_train_tune, X1_test, Y_train_tune, Y_test = train_test_split(X1_train, y_train, test_size = .3)\n",
    "            LR = LogisticRegression(C=c, init=init, scale=scale)\n",
    "            %time LR.fit(X1_train_tune, Y_train_tune)\n",
    "            score = auroc(Y_test, LR.predict_proba(X1_test))\n",
    "            print 'C:%f\\tinit:%s\\tscale:%s\\tscore:%f' % (c, init, scale, score)\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                C_opt = c\n",
    "                init_opt = init\n",
    "                scale_opt = scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = [0.0, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "def select_reg_parameter(C, X, Y):\n",
    "    return C.index(max(C))\n",
    "\n",
    "index = select_reg_parameter(C, X1, Y)\n",
    "print index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем наилучшее значение $C$, и классифицируем неизвестных пользователей и строим ROC-кривую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(X, Y, test_size, C):\n",
    "    tpr = [1] * 2400\n",
    "    fpr = [0.01] * 2400\n",
    "    roc_auc = 0.51\n",
    "    \n",
    "    return tpr, fpr, roc_auc\n",
    "\n",
    "tpr, fpr, roc_auc = classify(X1, Y, 0.3, C[index])\n",
    "\n",
    "print \"Area under the ROC curve : %f\" % roc_auc\n",
    "\n",
    "def plot_roc_curve(tpr, fpr, roc_auc):\n",
    "    \"\"\"Plot ROC curve\"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return\n",
    "\n",
    "plot_roc_curve(tpr, fpr, roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью полученной модели предсказываем категории для неизвестных пользователей из соревнования и загружаем на kaggle в нужном формате. ДЗ принимается только при наличии загруженных данных на kaggle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
