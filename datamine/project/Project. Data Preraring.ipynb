{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "CONSUMER_KEY = \"eTG832aIi0pyU6EjfoTGge6gx\"\n",
    "CONSUMER_SECRET = \"mjvQFaovxMuRJ0U5XpdYfPsmmqiaZFNsL7g4qkk942OdDip6hG\"\n",
    "\n",
    "ACCESS_TOKEN_KEY = \"780018504787488769-KVrRy17YTgqcUzrM32ykuYipvptNKvB\"\n",
    "ACCESS_TOKEN_SECRET = \"qtZmbBAiOrzaBxwGNdlP0bfVA3cz2AWmsv0kq1jfdIOEb\"\n",
    "\n",
    "api = twitter.Api(consumer_key=CONSUMER_KEY, \n",
    "                  consumer_secret=CONSUMER_SECRET, \n",
    "                  access_token_key=ACCESS_TOKEN_KEY, \n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET,\n",
    "                  sleep_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test_submition.csv\")\n",
    "test.cls = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user_twts (u_id):\n",
    "    kaggle_date = 1474243200\n",
    "    timeline = []\n",
    "    timeline = api.GetUserTimeline(user_id=u_id, count=200, include_rts=False, exclude_replies=True)\n",
    "    for i in xrange(20):\n",
    "        if len(timeline) == 0: return []\n",
    "        oldest_twt_id = timeline.pop().id\n",
    "        timeline += api.GetUserTimeline(user_id=u_id, max_id=oldest_twt_id, count=200, include_rts=False, exclude_replies=True) \n",
    "        if timeline[-1].created_at_in_seconds < kaggle_date:\n",
    "            print \"timeline get iterations:\", i\n",
    "            break\n",
    "    oldest_twt_id = timeline.pop().id\n",
    "    timeline += api.GetUserTimeline(user_id=u_id, max_id=oldest_twt_id, count=200, include_rts=False, exclude_replies=True) \n",
    "    if timeline[-1].created_at_in_seconds > kaggle_date: \n",
    "        print \"BAD_USER\"\n",
    "        bad_users.add(u_id)\n",
    "    return timeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = nltk.RegexpTokenizer('[a-z]+')\n",
    "\n",
    "def tokenize_twt(twt):\n",
    "    text = twt.text\n",
    "    #normalization\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text.lower()) if not unicodedata.combining(c))\n",
    "    #deleting URL's\n",
    "    text = re.sub('https?://\\S+', '', text)\n",
    "    #deleting HTML symbols\n",
    "    text = re.sub('&\\w+;', '', text)    \n",
    "\n",
    "    words = tokenizer.tokenize(text)\n",
    "    tokens = [wnl.lemmatize(word) for word in words if word not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "def get_user_vocab(twts):\n",
    "    vocab = {}\n",
    "    for twt in twts:\n",
    "        tokens = tokenize_twt(twt)\n",
    "        for token in tokens:\n",
    "            if token in vocab:\n",
    "                vocab[token] += 1\n",
    "            else:\n",
    "                vocab[token] = 1\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_tokens = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_users = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downloaded_users = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1464/11947 [00:18<02:10, 80.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD_USER\n",
      "63517561 642 downloaded 1585 words in vocab\n",
      "BAD_USER\n",
      "65552940 673 downloaded 2327 words in vocab\n",
      "timeline get iterations: 1\n",
      "1031499828 204 downloaded 825 words in vocab\n",
      "timeline get iterations: 0\n",
      "2606851334 587 downloaded 2750 words in vocab\n",
      "timeline get iterations: 0\n",
      "219549026 51 downloaded 270 words in vocab\n",
      "timeline get iterations: 0\n",
      "63100957 598 downloaded 2209 words in vocab\n",
      "timeline get iterations: 9\n",
      "16860135 577 downloaded 2232 words in vocab\n",
      "timeline get iterations: 12\n",
      "152987478 2986 downloaded 3772 words in vocab\n",
      "timeline get iterations: 1\n",
      "59085872 466 downloaded 1800 words in vocab\n",
      "timeline get iterations: 12\n",
      "193487520 221 downloaded 329 words in vocab\n",
      "timeline get iterations: 10\n",
      "742994089 759 downloaded 2105 words in vocab\n",
      "timeline get iterations: 0\n",
      "2395121324 178 downloaded 363 words in vocab\n",
      "BAD_USER\n",
      "1377836916 1082 downloaded 1787 words in vocab\n",
      "timeline get iterations: 5\n",
      "19991010 793 downloaded 2143 words in vocab\n",
      "timeline get iterations: 1\n",
      "138134164 320 downloaded 1033 words in vocab\n",
      "timeline get iterations: 12\n",
      "330033713 1349 downloaded 2202 words in vocab\n",
      "error\n",
      "1146499303 0 downloaded 0 words in vocab\n",
      "timeline get iterations: 6\n",
      "2362598966 39 downloaded 103 words in vocab\n",
      "timeline get iterations: 0\n",
      "2314480513 378 downloaded 1247 words in vocab\n",
      "timeline get iterations: 4\n",
      "158513165 225 downloaded 570 words in vocab\n",
      "timeline get iterations: 0\n",
      "17060480 334 downloaded 1460 words in vocab\n",
      "BAD_USER\n",
      "735505209237995520 414 downloaded 948 words in vocab\n",
      "BAD_USER\n",
      "17094323 954 downloaded 2271 words in vocab\n",
      "BAD_USER\n",
      "442392906 597 downloaded 1708 words in vocab\n",
      "timeline get iterations: 0\n",
      "63103100 450 downloaded 1752 words in vocab\n",
      "timeline get iterations: 5\n",
      "275843220 312 downloaded 1018 words in vocab\n",
      "timeline get iterations: 1\n",
      "758172822 301 downloaded 1376 words in vocab\n",
      "timeline get iterations: 0\n",
      "748634697899479040 27 downloaded 84 words in vocab\n",
      "3193263449 0 downloaded 0 words in vocab\n",
      "timeline get iterations: 0\n",
      "2808566649 448 downloaded 1203 words in vocab\n",
      "timeline get iterations: 4\n",
      "3130513437 280 downloaded 813 words in vocab\n",
      "timeline get iterations: 8\n",
      "109042331 547 downloaded 1472 words in vocab\n",
      "timeline get iterations: 0\n",
      "739506114501431296 365 downloaded 1118 words in vocab\n",
      "timeline get iterations: 4\n",
      "528928538 347 downloaded 868 words in vocab\n",
      "timeline get iterations: 12\n",
      "124632778 1142 downloaded 2890 words in vocab\n",
      "timeline get iterations: 7\n",
      "58993886 1012 downloaded 1771 words in vocab\n",
      "timeline get iterations: 0\n",
      "30689319 172 downloaded 508 words in vocab\n",
      "BAD_USER\n",
      "1314336656 477 downloaded 1251 words in vocab\n",
      "timeline get iterations: 1\n",
      "737083051281256448 289 downloaded 857 words in vocab\n",
      "timeline get iterations: 3\n",
      "2762497063 905 downloaded 1647 words in vocab\n",
      "timeline get iterations: 8\n",
      "26099631 2153 downloaded 1958 words in vocab\n",
      "timeline get iterations: 1\n",
      "2307816974 81 downloaded 482 words in vocab\n",
      "timeline get iterations: 0\n",
      "1216972788 138 downloaded 506 words in vocab\n",
      "timeline get iterations: 0\n",
      "926196294 83 downloaded 462 words in vocab\n",
      "timeline get iterations: 0\n",
      "318744475 88 downloaded 189 words in vocab\n",
      "timeline get iterations: 8\n",
      "128899888 806 downloaded 2343 words in vocab\n",
      "timeline get iterations: 0\n",
      "2541741991 530 downloaded 1704 words in vocab\n",
      "timeline get iterations: 15\n",
      "309958674 1190 downloaded 2521 words in vocab\n",
      "timeline get iterations: 8\n",
      "276165142 308 downloaded 1517 words in vocab\n",
      "timeline get iterations: 11\n",
      "141108981 550 downloaded 1715 words in vocab\n",
      "timeline get iterations: 3\n",
      "41564418 274 downloaded 850 words in vocab\n",
      "BAD_USER\n",
      "67398165 1129 downloaded 1337 words in vocab\n",
      "timeline get iterations: 0\n",
      "22300012 187 downloaded 981 words in vocab\n",
      "timeline get iterations: 0\n",
      "109270628 349 downloaded 616 words in vocab\n",
      "timeline get iterations: 12\n",
      "14191378 1376 downloaded 3326 words in vocab\n",
      "timeline get iterations: 0\n",
      "241157629 46 downloaded 242 words in vocab\n",
      "BAD_USER\n",
      "498547375 3241 downloaded 6098 words in vocab\n",
      "timeline get iterations: 11\n",
      "3014248472 335 downloaded 422 words in vocab\n",
      "BAD_USER\n",
      "1921329415 1837 downloaded 4329 words in vocab\n",
      "timeline get iterations: 0\n",
      "2981539302 384 downloaded 1399 words in vocab\n",
      "timeline get iterations: 0\n",
      "405147475 105 downloaded 280 words in vocab\n",
      "timeline get iterations: 0\n",
      "2840945764 273 downloaded 986 words in vocab\n",
      "timeline get iterations: 0\n",
      "55582896 222 downloaded 822 words in vocab\n",
      "BAD_USER\n",
      "713112567871311873 120 downloaded 478 words in vocab\n",
      "timeline get iterations: 3\n",
      "22651083 702 downloaded 1655 words in vocab\n",
      "BAD_USER\n",
      "2832896837 685 downloaded 2560 words in vocab\n",
      "timeline get iterations: 6\n",
      "1431588133 108 downloaded 385 words in vocab\n",
      "BAD_USER\n",
      "46812198 1133 downloaded 2899 words in vocab\n",
      "timeline get iterations: 0\n",
      "1962918888 69 downloaded 276 words in vocab\n",
      "timeline get iterations: 0\n",
      "1649225755 229 downloaded 817 words in vocab\n",
      "timeline get iterations: 4\n",
      "1945769556 622 downloaded 2021 words in vocab\n",
      "timeline get iterations: 8\n",
      "67547596 302 downloaded 1042 words in vocab\n",
      "BAD_USER\n",
      "1883294683 58 downloaded 335 words in vocab\n",
      "timeline get iterations: 0\n",
      "18252394 388 downloaded 1597 words in vocab\n",
      "timeline get iterations: 0\n",
      "3129440050 52 downloaded 328 words in vocab\n",
      "BAD_USER\n",
      "1012792830 393 downloaded 1212 words in vocab\n",
      "timeline get iterations: 4\n",
      "2605254031 228 downloaded 787 words in vocab\n",
      "BAD_USER\n",
      "231918084 734 downloaded 1193 words in vocab\n",
      "timeline get iterations: 0\n",
      "3102908274 219 downloaded 1115 words in vocab\n",
      "timeline get iterations: 6\n",
      "4757210488 489 downloaded 879 words in vocab\n",
      "timeline get iterations: 4\n",
      "1702968546 676 downloaded 1716 words in vocab\n",
      "timeline get iterations: 0\n",
      "93579645 187 downloaded 669 words in vocab\n",
      "BAD_USER\n",
      "936981026 831 downloaded 3356 words in vocab\n",
      "timeline get iterations: 7\n",
      "3002492483 1991 downloaded 572 words in vocab\n",
      "timeline get iterations: 13\n",
      "22490294 2976 downloaded 4532 words in vocab\n",
      "timeline get iterations: 0\n",
      "314487980 70 downloaded 413 words in vocab\n",
      "timeline get iterations: 2\n",
      "211888307 625 downloaded 1738 words in vocab\n",
      "BAD_USER\n",
      "15147882 181 downloaded 677 words in vocab\n",
      "BAD_USER\n",
      "109868594 3242 downloaded 7244 words in vocab\n",
      "timeline get iterations: 3\n",
      "703921664006819840 951 downloaded 952 words in vocab\n",
      "timeline get iterations: 16\n",
      "error\n",
      "2958747878 0 downloaded 0 words in vocab\n",
      "error\n",
      "84634930 0 downloaded 0 words in vocab\n",
      "error\n",
      "737055606599786496 0 downloaded 0 words in vocab\n",
      "timeline get iterations: 1\n",
      "2357780814 35 downloaded 151 words in vocab\n",
      "error\n",
      "281803065 0 downloaded 0 words in vocab\n",
      "timeline get iterations: 0\n",
      "3220443583 115 downloaded 222 words in vocab\n",
      "timeline get iterations: 8\n",
      "84119491 1061 downloaded 2226 words in vocab\n",
      "timeline get iterations: 6\n",
      "363821003 1792 downloaded 5511 words in vocab\n",
      "timeline get iterations: 1\n",
      "43804732 389 downloaded 1624 words in vocab\n",
      "timeline get iterations: 5\n",
      "2341119207 129 downloaded 588 words in vocab\n",
      "BAD_USER\n",
      "1067653219 7 downloaded 24 words in vocab\n",
      "timeline get iterations: 6\n",
      "23563066 358 downloaded 1235 words in vocab\n",
      "BAD_USER\n",
      "2499273312 590 downloaded 1431 words in vocab\n",
      "BAD_USER\n",
      "114345117 776 downloaded 2504 words in vocab\n",
      "2281290679 0 downloaded 0 words in vocab\n",
      "timeline get iterations: 8\n",
      "2352878573 1425 downloaded 1936 words in vocab\n",
      "timeline get iterations: 4\n",
      "2361506384 19 downloaded 92 words in vocab\n",
      "timeline get iterations: 0\n",
      "905933114 204 downloaded 888 words in vocab\n",
      "BAD_USER\n",
      "2851157944 180 downloaded 394 words in vocab\n",
      "BAD_USER\n",
      "3163148070 383 downloaded 1654 words in vocab\n",
      "timeline get iterations: 0\n",
      "61542733 127 downloaded 689 words in vocab\n",
      "timeline get iterations: 11\n",
      "217721309 196 downloaded 592 words in vocab\n",
      "error\n",
      "2469084638 0 downloaded 0 words in vocab\n",
      "timeline get iterations: 6\n",
      "3015333543 270 downloaded 931 words in vocab\n",
      "1974843926 0 downloaded 0 words in vocab\n",
      "BAD_USER\n",
      "371873865 44 downloaded 255 words in vocab\n",
      "timeline get iterations: 2\n",
      "203357948 304 downloaded 772 words in vocab\n",
      "BAD_USER\n",
      "7540692 2283 downloaded 4651 words in vocab\n",
      "timeline get iterations: 0\n",
      "127054240 481 downloaded 1545 words in vocab\n",
      "timeline get iterations: 1\n",
      "70085895 797 downloaded 1615 words in vocab\n",
      "timeline get iterations: 0\n",
      "1180030728 57 downloaded 225 words in vocab\n",
      "timeline get iterations: 14\n",
      "156608755 264 downloaded 500 words in vocab\n",
      "timeline get iterations: 0\n",
      "25138288 318 downloaded 1323 words in vocab\n",
      "timeline get iterations: 8\n",
      "2306518984 1429 downloaded 3594 words in vocab\n",
      "BAD_USER\n",
      "230941628 933 downloaded 941 words in vocab\n",
      "timeline get iterations: 3\n",
      "36739872 320 downloaded 1225 words in vocab\n",
      "timeline get iterations: 4\n",
      "244126075 1366 downloaded 2221 words in vocab\n",
      "timeline get iterations: 5\n",
      "4225263193 336 downloaded 1045 words in vocab\n",
      "timeline get iterations: 12\n",
      "1364594401 1089 downloaded 2855 words in vocab\n",
      "BAD_USER\n",
      "15165643 3149 downloaded 2832 words in vocab\n",
      "timeline get iterations: 11\n",
      "2239410991 842 downloaded 2523 words in vocab\n",
      "timeline get iterations: 6\n",
      "317135855 394 downloaded 1936 words in vocab\n",
      "timeline get iterations: 0\n",
      "16968123 249 downloaded 1137 words in vocab\n",
      "timeline get iterations: 1\n",
      "145741943 317 downloaded 1521 words in vocab\n",
      "timeline get iterations: 0\n",
      "181806097 334 downloaded 1691 words in vocab\n",
      "BAD_USER\n",
      "3429088955 984 downloaded 3192 words in vocab\n",
      "timeline get iterations: 0\n",
      "2289859375 38 downloaded 149 words in vocab\n",
      "timeline get iterations: 6\n",
      "27107647 1790 downloaded 3446 words in vocab\n",
      "timeline get iterations: 0\n",
      "35032363 280 downloaded 1161 words in vocab\n",
      "timeline get iterations: 3\n",
      "242266975 527 downloaded 1874 words in vocab\n",
      "timeline get iterations: 0\n",
      "261029793 144 downloaded 293 words in vocab\n",
      "timeline get iterations: 5\n",
      "294697643 722 downloaded 898 words in vocab\n",
      "timeline get iterations: 3\n",
      "213807285 232 downloaded 784 words in vocab\n",
      "timeline get iterations: 2\n",
      "20097100 585 downloaded 1552 words in vocab\n",
      "timeline get iterations: 7\n",
      "16122674 386 downloaded 1091 words in vocab\n",
      "timeline get iterations: 1\n",
      "3073813809 565 downloaded 1086 words in vocab\n",
      "timeline get iterations: 0\n",
      "63795206 367 downloaded 1715 words in vocab\n",
      "timeline get iterations: 0\n",
      "2511440153 51 downloaded 230 words in vocab\n",
      "timeline get iterations: 1\n",
      "35568081 786 downloaded 1924 words in vocab\n",
      "BAD_USER\n",
      "68125879 452 downloaded 1226 words in vocab\n",
      "timeline get iterations: 0\n",
      "2589222841 58 downloaded 218 words in vocab\n",
      "BAD_USER\n",
      "941221358 218 downloaded 400 words in vocab\n",
      "error\n",
      "26297078 0 downloaded 0 words in vocab\n",
      "timeline get iterations: 13\n",
      "1945994221 591 downloaded 1764 words in vocab\n",
      "BAD_USER\n",
      "2797404271 902 downloaded 2126 words in vocab\n",
      "timeline get iterations: 3\n",
      "49754809 1095 downloaded 3896 words in vocab\n",
      "BAD_USER\n",
      "1207668950 3213 downloaded 4101 words in vocab\n",
      "error\n",
      "769063723080290304 0 downloaded 0 words in vocab\n",
      "743944071329157120 0 downloaded 0 words in vocab\n",
      "timeline get iterations: 3\n",
      "756959111716171777 1195 downloaded 767 words in vocab\n",
      "timeline get iterations: 9\n",
      "42935811 1704 downloaded 3820 words in vocab\n",
      "timeline get iterations: 14\n",
      "15703248 1661 downloaded 2077 words in vocab\n",
      "timeline get iterations: 11\n",
      "1544091762 1053 downloaded 1940 words in vocab\n",
      "timeline get iterations: 1\n",
      "4427538260 537 downloaded 1350 words in vocab\n",
      "timeline get iterations: 10\n",
      "255948953 667 downloaded 2159 words in vocab\n",
      "BAD_USER\n",
      "2161949366 34 downloaded 127 words in vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-8e1e6a6ca109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0muser_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtwts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_twts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtwts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-3f0913d8a4ea>\u001b[0m in \u001b[0;36mget_user_twts\u001b[0;34m(u_id)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moldest_twt_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtimeline\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetUserTimeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moldest_twt_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_rts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_replies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at_in_seconds\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mkaggle_date\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"timeline get iterations:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dima/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36mGetUserTimeline\u001b[0;34m(self, user_id, screen_name, since_id, max_id, count, include_rts, trim_user, exclude_replies)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exclude_replies'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RequestUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ParseAndCheckTwitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dima/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36m_RequestUrl\u001b[0;34m(self, url, verb, data, json)\u001b[0m\n\u001b[1;32m   4750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4751\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4752\u001b[0;31m                    \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4754\u001b[0m                    \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "from twitter import TwitterError\n",
    "from tqdm import tqdm\n",
    "user_ids = pd.concat([train, test])['uid']\n",
    "for uid in tqdm(user_ids):\n",
    "    if uid in downloaded_users: continue\n",
    "    if len(user_tokens) >= 1000:\n",
    "        print 'TRYING TO SAVE PICKLE'\n",
    "        with open('user_tokens_'+str(len(downloaded_users))+'.pkl', 'wb') as f:\n",
    "            pickle.dump(user_tokens, f, pickle.HIGHEST_PROTOCOL)\n",
    "            print \"pickle dumped\", 'user_tokens_'+str(len(downloaded_users))+'.pkl'\n",
    "            user_tokens = {}\n",
    "    try:    \n",
    "        twts = get_user_twts(uid)\n",
    "    except TwitterError:\n",
    "        twts = []\n",
    "        print 'error'\n",
    "        next\n",
    "    vocab = get_user_vocab(twts)\n",
    "    user_tokens[uid] = vocab\n",
    "    downloaded_users.add(uid)\n",
    "    print uid, len(twts), 'downloaded', len(vocab), 'words in vocab'\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'twitter' from '/home/dima/anaconda2/lib/python2.7/site-packages/twitter/__init__.pyc'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload (twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(downloaded_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def save_downloaded_users_set():\n",
    "    t = int(time.time())\n",
    "    with open(str(t)+'_downloaded_users.pkl', 'wb') as f:\n",
    "        pickle.dump(downloaded_users, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print \"pickle dumped\", str(t)+'_downloaded_users.pkl'\n",
    "    return\n",
    "\n",
    "def save_bad_users_set():\n",
    "    t = int(time.time())\n",
    "    with open(str(t)+'_bad_users.pkl', 'wb') as f:\n",
    "        pickle.dump(bad_users, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print \"pickle dumped\", str(t)+'_bad_users.pkl'\n",
    "    return\n",
    "\n",
    "def save_user_tokens():\n",
    "    t = int(time.time())\n",
    "    with open(str(t)+'_user_tokens.pkl', 'wb') as f:\n",
    "        pickle.dump(user_tokens, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print \"pickle dumped\", str(t)+'_user_tokens.pkl'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle dumped 1482080100_downloaded_users.pkl\n",
      "pickle dumped 1482080101_bad_users.pkl\n",
      "pickle dumped 1482080101_user_tokens.pkl\n"
     ]
    }
   ],
   "source": [
    "save_downloaded_users_set()\n",
    "save_bad_users_set()\n",
    "save_user_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_pickle(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load test\n",
      "downloaded 1629\n",
      "bad 338\n",
      "tokens 629\n"
     ]
    }
   ],
   "source": [
    "print 'load test'\n",
    "\n",
    "print 'downloaded', len(load_pickle('1482080100_downloaded_users.pkl'))\n",
    "print 'bad', len(load_pickle('1482080101_bad_users.pkl'))\n",
    "print 'tokens', len(load_pickle('1482080101_user_tokens.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_users1482077419.43.pkl\t   test_submition.csv\r\n",
      "bad_users1482077865.63.pkl\t   train.csv\r\n",
      "downloaded_users1482077419.34.pkl  user_tokens1482077419.45.pkl\r\n",
      "downloaded_users1482077865.54.pkl  user_tokens_1482077865.64.pkl\r\n",
      "Project. Data Preraring.ipynb\t   user_tokens_1.pkl\r\n",
      "test.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
